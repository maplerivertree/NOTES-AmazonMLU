{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data <br>\n",
    "Let's use the data snippet from last time to load our data back in. I'll also fix the randomseed so the notebook is determininistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "np.random.seed(8675309)\n",
    " \n",
    "eider.s3.download('s3://eider-datasets/mlu/DATA_Training.csv','/tmp/DATA_Training.csv')\n",
    "eider.s3.download('s3://eider-datasets/mlu/DATA_Public_Test.csv','/tmp/DATA_Public_Test.csv')\n",
    "train = pd.read_csv('/tmp/DATA_Training.csv', na_values = 'null')\n",
    "public_test = pd.read_csv('/tmp/DATA_Public_Test.csv', na_values = 'null')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 0<br>\n",
    "Last week we did some data cleaning and feature engineering. It is a good idea if you start from that point this week, so start by bringing over whatever set of cleaned and engineered features you decided upon for last week. We will build based off of that point. Note: please leave off any feature scaling for the moment, as we will include it in the next question for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER 0 ###\n",
    " \n",
    "#####  Start deal with missing values  #####\n",
    "# Deal with missing values for scores, for each score column, Use pandas fillna to replace missing value with the mean of the column.\n",
    "score_columns = ['score1','score2','score3','score4','score5']\n",
    "train.fillna(train[score_columns].mean(), inplace = True)\n",
    "public_test.fillna(train[score_columns].mean(), inplace = True)\n",
    " \n",
    "# Deal with missing value for CIL and contact_type\n",
    "cil_columns_values = {'CIL1' : 'Not Specified', 'CIL2' : 'Not Specified', 'CIL3' : 'Not Specified', 'CLI4' : 'Not Specified', 'IL1' : 'Not Specified', 'IL2' : 'Not Specified', 'IL3' : 'Not Specified', 'IL4' : 'Not Specified'}\n",
    "contact_type_value = {'contact_type' : 0.0}\n",
    "# FOR CIL1-CIL4, AND IL1-IL4, fill in with 'Not Specified'\n",
    "train.fillna(cil_columns_values, inplace = True) \n",
    "public_test.fillna(cil_columns_values, inplace = True) \n",
    "# FOR contact_type, fill in with most common value 0.0\n",
    "train.fillna(contact_type_value, inplace = True) \n",
    "public_test.fillna(contact_type_value, inplace = True) \n",
    " \n",
    "#####  End of deal with missing values  #####\n",
    " \n",
    "#####  Start categorical OneHot encoding  #####\n",
    "issue_features = ['CIL1', 'CIL2', 'CIL3', 'CLI4', 'IL1', 'IL2', 'IL3', 'IL4','device']\n",
    "# Try to collect all possible values of each column\n",
    "for feature in issue_features:\n",
    "    unique_elements = pd.concat([train[feature], public_test[feature]]).unique().tolist()\n",
    "    train[feature] = train[feature].astype('category').cat.set_categories(unique_elements)\n",
    "    public_test[feature] = public_test[feature].astype('category').cat.set_categories(unique_elements)\n",
    "public_test = pd.get_dummies(public_test)\n",
    "train = pd.get_dummies(train)\n",
    "#####  End categorical OneHot encoding  #####\n",
    " \n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 <br>\n",
    "Let's combine a few techniques together into a single pipeline for tuning later. For this question we will eventually use a DecisionTreeClassifier to produce our output. If you recall our discussion of decision trees they only made decisions based on single variables. However, it is quite reasonable to want to make decisions based on combinations of features. To do so, we can transform our features using a PCA first in an attempt to offer our algorithm decorrelated features to work from.\n",
    "\n",
    "To this end, use Pipeline to take in your data, apply the StandardScaler, transform the data using a PCA, and finally feed the result into a DecisionTreeClassifier. We'll get to grid searching later, but for right now, run cross_val_score with this pipeline as the classifier to see how it does.\n",
    "\n",
    "Note: when experimenting on your own, you might want to transform your features in many different ways. To do so you should examine FeatureUnion as a companion to pipeline that allows for parallel computation, not serial computation. If you want to see an example of it being used, take a look here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "### ANSWER 1 ###\n",
    "# Using Pipeline to help us keep our code organized.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "# Split train datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop('response',axis=1), \n",
    "                                                    train['response'], test_size=0.20, \n",
    "                                                    random_state=101)\n",
    " \n",
    "# Build a Pipeline with StandardScaler, PCA and DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=False)\n",
    "pca = PCA()\n",
    "print(\"-----------------------------------Build a Pipeline with StandardScaler, PCA and DecisionTreeClassifier---------------------------------------------- \")\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('pca', pca), ('clf', clf)])\n",
    "print(\"Create a Pipeline, apply the StandardScaler, transform the data using a PCA, and finally try DecisionTreeClassifier\")\n",
    "print(\"Let's run cross_val_score with this pipeline and see the score: \")\n",
    "print(cross_val_score(pipe, X_train, y_train, cv=5))\n",
    "print(\"-----------------------------------End---------------------------------------------- \")\n",
    " \n",
    "# Transform our features in different ways by using FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import KernelPCA\n",
    "transformers = [('linear_pca', PCA()), ('kernel_pca', KernelPCA())]\n",
    "combined = FeatureUnion(transformers)\n",
    "pipeline_with_featureUnion = Pipeline([\n",
    "    # Apply the StandardScaler\n",
    "    ('scaler', scaler),\n",
    "    \n",
    "    # Use FeatureUnion to combine the features from PCA and kenel_pca\n",
    "    ('union', combined),\n",
    " \n",
    "    # Use DecisionTreeClassifier on the combined features\n",
    "    ('clf', clf),\n",
    "])\n",
    "print(\"-----------------------------------Experiment: Pipeline with FeatureUnion---------------------------------------------- \")\n",
    "print(\"Create a Pipeline with FeatureUnion, apply the StandardScaler, transform the data using a PCA and Kenel_PCA, and finally try DecisionTreeClassifier\")\n",
    "print(\"Let's run cross_val_score with this pipeline with FeatureUnion and see the score: \")\n",
    "pipeline_with_featureUnion.set_params(union__linear_pca__n_components=10, union__kernel_pca__n_components=10)\n",
    "print(cross_val_score(pipeline_with_featureUnion, X_train, y_train, cv=5))\n",
    "print(\"-----------------------------------End---------------------------------------------- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to tune this a bit. The first thing you might notice is that the PCA makes the above fit rather slow. We can counteract that by restricting the number of principle components it computes using n_components. This can also help counteract overfitting. However, to select the best possible values, we'd like to do a grid search. Thus the question is, how do you grid search over a parameter burried inside a pipeline?\n",
    "<br>\n",
    "Question 2 <br>\n",
    "Take a look at this example. Here we see a similar process being done with GridSearchCV and a pipeline. Perform a similar sweep with n_components in the range {5,10,20} and class_weight associated to class one from {1,4,16,64} for our dataset. Don't forget to set the scoring method to 'f1'. From the fit model, you can get the best score using best_score_, the best model using best_model_, and the best parameters using best_params_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "### ANSWER 2 ###\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    " \n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'pca__n_components': [5,10,20],\n",
    "    'clf__class_weight': [{1:1},{1:4}, {1:16},{1:64}]\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, iid=False, cv=5, scoring='f1')\n",
    "search.fit(X_train, y_train)\n",
    " \n",
    "print(\"Best Parameter {}:\".format(search.best_params_))\n",
    "print(\"Best Score {}:\".format(search.best_score_))\n",
    "print(\"Best Model {}:\".format(search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably not as good as the model you finally arrived at last week, but at least it shows you how you can chain multiple techniques together and easily search over many possible values for the various parameters in each stage.\n",
    "\n",
    "Since this model starts with a PCA, it is no longer possible to interpret the features. They have become essentially arbitrary linear combinations of the dataset. However, we do know that the top principle components correspond to the directions of maximum variance in the data, so one could hope that these are the most important features for our data.\n",
    "<br>\n",
    "Question 3 <br>\n",
    "After the grid search above finishes, you are given a trained model that contains a decision tree as the final step. Plot the feature importances (.feature_importances_ of the decision tree in the best estimator). Are the importances of the early features (the higest variance PCs) larger than the later ones? If not, what does that tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "### ANSWER 3 ###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "importances = search.best_estimator_.named_steps.clf.feature_importances_\n",
    "plt.bar(np.arange(10), importances, width=0.8, align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3 <br>\n",
    "ARE THE IMPORTANCES OF THE EARLY FEATURES (THE HIGEST VARIANCE PCS) LARGER THAN THE LATER ONES? IF NOT, WHAT DOES THAT TELL US?\n",
    "The importances of the early features (the higest variance PCs) are less than the later ones.\n",
    "It tells us that the later PCs are more important to our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 <br>\n",
    "Finally, lets look in to the learning curve of our best-fit model (a nice example here). Set the parameters of your pipeline to the ones identified by the cross-validation. What can you say about our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Answer 4 ###\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    " \n",
    " \n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    " \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    " \n",
    "    title : string\n",
    "        Title for the chart.\n",
    " \n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    " \n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    " \n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    " \n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    " \n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    " \n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    " \n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    " \n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    " \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    " \n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    " \n",
    "title = \"Learning Curves of our best_estimator\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "estimator = search.best_estimator_\n",
    "plot_learning_curve(estimator, title, X_train, y_train,ylim=(0.7, 1.01), cv=cv, n_jobs=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 4 <br>\n",
    "WHAT CAN YOU SAY ABOUT OUR MODEL?\n",
    "We can see clearly that the training score is still around the maximum and the validation score could not be increased with more training samples.\n",
    "we can fairly say our model has overfitting issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5 <br>\n",
    "As last week, now take the time to try things out! Being able to use Pipeline (and FeatureUnion if needed), along with GridSearchCV should reduce the burden on lots of the boilerplate code. Try different ways of encoding features, methods of dimension reduction, or learning algorithms. In particular, don't feel constrained to just those topics we've covered in detail! Poke around and just try things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER 5 ###\n",
    " \n",
    "# Using Pipeline to help us keep our code organized.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "# Split train datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop('response',axis=1), \n",
    "                                                    train['response'], test_size=0.10, \n",
    "                                                    random_state=101)\n",
    "print(\"-----------------------------------Experiment 1: LogisticRegression with PCA ---------------------------------------------- \")\n",
    "print(\"Create a Pipeline with FeatureUnion, apply the StandardScaler, transform the data using a PCA, and finally try LogisticRegression\")\n",
    "print(\"Run GridSearchCV on this pipeline to search the best parameters\")\n",
    "# Build a Pipeline with StandardScaler, PCA and LogisticRegression\n",
    "clf = LogisticRegression(random_state=0)\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=False)\n",
    "# Transform our features in different ways by using FeatureUnion\n",
    "transformers = [('pca', PCA())]\n",
    "combined = FeatureUnion(transformers)\n",
    "pipeline_with_featureUnion = Pipeline([\n",
    "    # Apply the StandardScaler\n",
    "    ('scaler', scaler),\n",
    "    \n",
    "    # Use FeatureUnion to combine the features from PCA and kenel_pca\n",
    "    ('union', combined),\n",
    " \n",
    "    # Use DecisionTreeClassifier on the combined features\n",
    "    ('clf', clf),\n",
    "])\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'union__pca__n_components': [10],\n",
    "    'clf__C':np.logspace(-3,3,7),\n",
    "    'clf__penalty':[\"l2\"],\n",
    "}\n",
    "search = GridSearchCV(pipeline_with_featureUnion, param_grid, iid=False, cv=5, scoring='f1')\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best Parameter {}:\".format(search.best_params_))\n",
    "print(\"Best Score {}:\".format(search.best_score_))\n",
    "print(\"Best Model {}:\".format(search.best_estimator_))\n",
    "print(\"-----------------------------------End---------------------------------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "# Split train datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop('response',axis=1), \n",
    "                                                    train['response'], test_size=0.10, \n",
    "                                                    random_state=101)\n",
    " \n",
    " \n",
    "print(\"-----------------------------------Experiment 2: SVC with PCA ---------------------------------------------- \")\n",
    "print(\"Create a Pipeline with FeatureUnion, apply the StandardScaler, transform the data using a PCA, and finally try SVC\")\n",
    "print(\"Run GridSearchCV on this pipeline to search the best parameters\")\n",
    "# Build a Pipeline with StandardScaler, KernalPCA and SVC\n",
    "clf = SVC()\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=False)\n",
    "# Transform our features in different ways by using FeatureUnion\n",
    "transformers = [('pca', PCA())]\n",
    "combined = FeatureUnion(transformers)\n",
    "pipeline_with_featureUnion = Pipeline([\n",
    "    # Apply the StandardScaler\n",
    "    ('scaler', scaler),\n",
    "    \n",
    "    # Use FeatureUnion to combine the features from PCA and kenel_pca\n",
    "    ('union', combined),\n",
    " \n",
    "    # Use DecisionTreeClassifier on the combined features\n",
    "    ('clf', clf),\n",
    "])\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'union__pca__n_components': [10],\n",
    "    'clf__kernel': ['rbf'],\n",
    "    'clf__gamma': [1e-3, 1e-4],\n",
    "    'clf__C': [1, 10, 100],\n",
    "}\n",
    "search = GridSearchCV(pipeline_with_featureUnion, param_grid, iid=False, cv=5, scoring='f1')\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best Parameter {}:\".format(search.best_params_))\n",
    "print(\"Best Score {}:\".format(search.best_score_))\n",
    "print(\"Best Model {}:\".format(search.best_estimator_))\n",
    "print(\"-----------------------------------End---------------------------------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "print(\"-----------------------------------Experiment 3: DecisionTreeClassifier with KenerlPCA ---------------------------------------------- \")\n",
    "print(\"Create a Pipeline with FeatureUnion, apply the StandardScaler, transform the data using Kenel_PCA, and finally try DecisionTreeClassifier\")\n",
    "print(\"Run GridSearchCV on this pipeline to search the best parameters\")\n",
    "# Build a Pipeline with StandardScaler, KernalPCA and DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "scaler = StandardScaler(copy=True, with_mean=False, with_std=False)\n",
    "# Transform our features in different ways by using FeatureUnion\n",
    "transformers = [('kernel_pca', KernelPCA())]\n",
    "combined = FeatureUnion(transformers)\n",
    "pipeline_with_featureUnion = Pipeline([\n",
    "    # Apply the StandardScaler\n",
    "    ('scaler', scaler),\n",
    "    \n",
    "    # Use FeatureUnion to combine the features from PCA and kenel_pca\n",
    "    ('union', combined),\n",
    " \n",
    "    # Use DecisionTreeClassifier on the combined features\n",
    "    ('clf', clf),\n",
    "])\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'union__kernel_pca__n_components': [5,10],\n",
    "    'clf__class_weight': [{1:1},{1:4}, {1:16},{1:64}]\n",
    "}\n",
    "search = GridSearchCV(pipeline_with_featureUnion, param_grid, iid=False, cv=5, scoring='f1')\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best Parameter {}:\".format(search.best_params_))\n",
    "print(\"Best Score {}:\".format(search.best_score_))\n",
    "print(\"Best Model {}:\".format(search.best_estimator_))\n",
    "print(\"-----------------------------------End---------------------------------------------- \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
