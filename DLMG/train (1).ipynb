{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train the neural network\n",
    "\n",
    "<br>\n",
    "<center><img src=\"support/robot.gif\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this section, we will discuss how to train a defined network with data. We first import the libraries. The new ones are `mxnet.init` for more weight initialization methods, the `datasets` and `transforms` to load and transform computer vision datasets, `matplotlib` for drawing, and `time` for benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd, gluon, init, autograd\n",
    "\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Training Dataset: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The handwritten digit MNIST dataset is one of the most commonly used datasets in deep learning. So we'll use it here.\n",
    "\n",
    "The dataset can be automatically downloaded through Gluon's `data.vision.datasets.MNIST` which is a subclass of `gluon.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (28, 28, 1) dtype: <class 'numpy.uint8'>\n",
      "Number of images: 60000\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(train=True)\n",
    "X, y = mnist_train[0]\n",
    "print('X shape: %s dtype: %s' % (X.shape, X.dtype))\n",
    "print(\"Number of images: %d\" % len(mnist_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In order to feed data into a Gluon model, we need to convert the images to the `(channel, height, weight)` format with a floating point data type. It can be done by `transforms.ToTensor`. In addition, we normalize all pixel values to be between 0 and 1. We chain these two transforms together and apply it to the first element of the data pair, namely the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Transform dataset using `data.vision.transforms.ToTensor`:\n",
    "- channel first, float32\n",
    "- Min-Max Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.transform_first(transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_data = gluon.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The returned `train_data` is an iterator that yields batches of images and labels pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1, 28, 28) (256,)\n"
     ]
    }
   ],
   "source": [
    "for data, label in train_data:\n",
    "    print(data.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We implement a simple neural network model introduced before. One difference here is that we changed the weight initialization method to `Xavier`, which is a popular choice for deep convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(120, activation=\"relu\"),\n",
    "        nn.Dense(84, activation=\"relu\"),\n",
    "        nn.Dense(10)\n",
    "    )\n",
    "net.initialize(init=init.Xavier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Besides the neural network, we need to define the loss function and optimization method for training. We will use standard softmax cross entropy loss for classification problems. It first performs softmax on the output to obtain the predicted probability, and then compares the label with the cross entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"support/cross_entropy.png\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The optimization method we pick is the standard stochastic gradient descent with constant learning rate of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'sgd', {'learning_rate': 0.1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"support/optimization.gif\" width=400></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The `trainer` is created with all parameters (both weights and gradients) in `net`. Later on, we only need to call the `step` method to update its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def acc(output, label):\n",
    "    # output: (batch, num_output) float32 ndarray\n",
    "    # label: (batch, ) int32 ndarray\n",
    "    acc = (output.argmax(axis=1) == label.astype('float32'))\n",
    "    return acc.mean().asscalar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we can implement the complete training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] Loss:0.589 Acc:0.837 Perf: 31231.4 img/sec\n",
      "Epoch[1] Loss:0.289 Acc:0.917 Perf: 30453.0 img/sec\n",
      "Epoch[2] Loss:0.233 Acc:0.934 Perf: 27167.5 img/sec\n",
      "Epoch[3] Loss:0.197 Acc:0.944 Perf: 28271.2 img/sec\n",
      "Epoch[4] Loss:0.172 Acc:0.951 Perf: 29715.1 img/sec\n",
      "Epoch[5] Loss:0.151 Acc:0.956 Perf: 29598.4 img/sec\n",
      "Epoch[6] Loss:0.134 Acc:0.962 Perf: 28834.3 img/sec\n",
      "Epoch[7] Loss:0.121 Acc:0.965 Perf: 30130.1 img/sec\n",
      "Epoch[8] Loss:0.110 Acc:0.969 Perf: 29800.6 img/sec\n",
      "Epoch[9] Loss:0.100 Acc:0.972 Perf: 28675.8 img/sec\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    tic = time()\n",
    "    for data, label in train_data:\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        \n",
    "        train_loss += loss.mean().asscalar()\n",
    "        train_acc += acc(output, label)\n",
    "\n",
    "  \n",
    "    print(\"Epoch[%d] Loss:%.3f Acc:%.3f Perf: %.1f img/sec\"%(\n",
    "        epoch, train_loss/len(train_data),\n",
    "        train_acc/len(train_data),\n",
    "        len(mnist_train)/(time()-tic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#validation dataset\n",
    "mnist_valid = gluon.data.vision.MNIST(train=False)\n",
    "\n",
    "valid_data = gluon.data.DataLoader(mnist_valid.transform_first(transforms.ToTensor()), \n",
    "                                   batch_size=batch_size, \n",
    "                                   num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Validation accuracy: 0.97'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_acc = 0.\n",
    "for data, label in valid_data:\n",
    "    output = net(data)\n",
    "    valid_acc += acc(output, label)\n",
    "    \n",
    "\"Validation accuracy: %.2f\"%(valid_acc/len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Finally, we save the trained parameters onto disk, so that we can use them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"support/save.gif\" width=600></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net.save_parameters('net.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training with Amazon SageMaker\n",
    "\n",
    "<br>\n",
    "<center><img src=\"support/cloud-upload.gif\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now let's see how to train the previously defined network on the aws cloud using Amazon Sagemaker to manage the  data. Let's import the sagemaker libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling the data\n",
    "\n",
    "Point to data location in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_location = 's3://{}/{}'.format(session.default_bucket(), 'data')\n",
    "output_location = 's3://{}/{}'.format(session.default_bucket(), 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MXNet Model Training script\n",
    "\n",
    "Package the training defined above and functions for inference into a script that's used as an entrypoint by sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m time\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmx\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m nd, gluon, init, autograd\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet.gluon\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m nn\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet.gluon.data.vision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1000\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--learning-rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--optimizer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33madam\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.9\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--wd\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.00001\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_args()\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_logger\u001b[39;49;00m(name):\r\n",
      "    logger = logging.getLogger(name)\r\n",
      "    log_format = \u001b[33m'\u001b[39;49;00m\u001b[33m%(asctime)s\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m%(levelname)s\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m%(name)s\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m%(message)s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    logging.basicConfig(format=log_format, level=logging.INFO)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m logger\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_data\u001b[39;49;00m(batch_size):\r\n",
      "    mnist_train = datasets.MNIST(train=\u001b[36mTrue\u001b[39;49;00m)\r\n",
      "    train_data = gluon.data.DataLoader(mnist_train.transform_first(transforms.ToTensor()), \r\n",
      "                                       batch_size=batch_size, \r\n",
      "                                       shuffle=\u001b[36mTrue\u001b[39;49;00m, \r\n",
      "                                       num_workers=\u001b[34m4\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    mnist_valid = gluon.data.vision.MNIST(train=\u001b[36mFalse\u001b[39;49;00m)\r\n",
      "    valid_data = gluon.data.DataLoader(mnist_valid.transform_first(transforms.ToTensor()), \r\n",
      "                                       batch_size=batch_size, \r\n",
      "                                       num_workers=\u001b[34m4\u001b[39;49;00m)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m train_data, train_data\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_net\u001b[39;49;00m():\r\n",
      "    net = nn.Sequential()\r\n",
      "    \u001b[34mwith\u001b[39;49;00m net.name_scope():\r\n",
      "        net.add(\r\n",
      "            nn.Flatten(),\r\n",
      "            nn.Dense(\u001b[34m120\u001b[39;49;00m, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\r\n",
      "            nn.Dense(\u001b[34m84\u001b[39;49;00m, activation=\u001b[33m\"\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\r\n",
      "            nn.Dense(\u001b[34m10\u001b[39;49;00m)\r\n",
      "        )\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m net\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32macc\u001b[39;49;00m(output, label):\r\n",
      "    \u001b[37m# output: (batch, num_output) float32 ndarray\u001b[39;49;00m\r\n",
      "    \u001b[37m# label: (batch, ) int32 ndarray\u001b[39;49;00m\r\n",
      "    acc = (output.argmax(axis=\u001b[34m1\u001b[39;49;00m) == label.astype(\u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m acc.mean().asscalar()\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(net, train_data, valid_data, epochs, batch_size, trainer, model_dir, ctx):\r\n",
      "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\r\n",
      "    \r\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(epochs):\r\n",
      "        train_loss, train_acc, valid_acc = \u001b[34m0.\u001b[39;49;00m, \u001b[34m0.\u001b[39;49;00m, \u001b[34m0.\u001b[39;49;00m\r\n",
      "        tic = time()\r\n",
      "        \u001b[34mfor\u001b[39;49;00m data, label \u001b[35min\u001b[39;49;00m train_data:\r\n",
      "            \u001b[34mwith\u001b[39;49;00m autograd.record():\r\n",
      "                output = net(data.as_in_context(ctx))\r\n",
      "                loss = softmax_cross_entropy(output, label.as_in_context(ctx))\r\n",
      "            loss.backward()\r\n",
      "\r\n",
      "            trainer.step(batch_size)\r\n",
      "\r\n",
      "            train_loss += loss.mean().asscalar()\r\n",
      "            train_acc += acc(output, label.as_in_context(ctx))\r\n",
      "        \r\n",
      "        \u001b[34mfor\u001b[39;49;00m data, label \u001b[35min\u001b[39;49;00m valid_data:\r\n",
      "            output = net(data.as_in_context(ctx))\r\n",
      "            valid_acc += acc(output, label.as_in_context(ctx))\r\n",
      "       \r\n",
      "  \r\n",
      "        logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch[\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m] Loss:\u001b[39;49;00m\u001b[33m%.3f\u001b[39;49;00m\u001b[33m Acc:\u001b[39;49;00m\u001b[33m%.3f\u001b[39;49;00m\u001b[33m|\u001b[39;49;00m\u001b[33m%.3f\u001b[39;49;00m\u001b[33m Perf: \u001b[39;49;00m\u001b[33m%.1f\u001b[39;49;00m\u001b[33m img/sec\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m%(\r\n",
      "        epoch, train_loss/\u001b[36mlen\u001b[39;49;00m(train_data),\r\n",
      "        train_acc/\u001b[36mlen\u001b[39;49;00m(train_data),\r\n",
      "        valid_acc/\u001b[36mlen\u001b[39;49;00m(valid_data),\r\n",
      "        \u001b[36mlen\u001b[39;49;00m(train_data._dataset)/(time()-tic)))\r\n",
      "    \r\n",
      "    net.save_parameters(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mnet.params\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\r\n",
      "    logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaved model params\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    logging.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mEnd of training\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    \r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    logging = get_logger(\u001b[31m__name__\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    options = parse_args()\r\n",
      "    \r\n",
      "    ctx = mx.gpu() \u001b[34mif\u001b[39;49;00m options.num_gpus > \u001b[34m0\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m mx.cpu()\r\n",
      "    train_data, validation_data = get_data(options.batch_size)\r\n",
      "    \r\n",
      "    net = get_net()\r\n",
      "    net.initialize(init=init.Xavier(), ctx=ctx)\r\n",
      "    \r\n",
      "    optimizer_params = {\u001b[33m'\u001b[39;49;00m\u001b[33mlearning_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: options.learning_rate, \u001b[33m'\u001b[39;49;00m\u001b[33mwd\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: options.wd}\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m options.optimizer == \u001b[33m'\u001b[39;49;00m\u001b[33msgd\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        optimizer_params[\u001b[33m'\u001b[39;49;00m\u001b[33mmomentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = options.momentum\r\n",
      "\r\n",
      "    trainer = gluon.Trainer(net.collect_params(), options.optimizer, optimizer_params)\r\n",
      "    \r\n",
      "    train(net, train_data, validation_data, options.epochs, options.batch_size, trainer, options.model_dir, ctx)\r\n",
      "    \r\n",
      "    \r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    net = get_net()\r\n",
      "    ctx = mx.gpu() \u001b[34mif\u001b[39;49;00m mx.context.num_gpus() > \u001b[34m0\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m mx.cpu()\r\n",
      "    net.load_parameters(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mnet.params\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), ctx)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m net\r\n",
      "    \r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtransform_fn\u001b[39;49;00m(net, data, input_content_type, output_content_type):\r\n",
      "    data_dict = json.loads(data.decode())\r\n",
      "    input_data = nd.array(data_dict[\u001b[33m'\u001b[39;49;00m\u001b[33minput\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    \r\n",
      "    ctx = mx.gpu() \u001b[34mif\u001b[39;49;00m mx.context.num_gpus() > \u001b[34m0\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m mx.cpu()\r\n",
      "    input_data = input_data.as_in_context(ctx)\r\n",
      "    pred = net(input_data)\r\n",
      "    \r\n",
      "    response = json.dumps(pred.asnumpy().tolist())\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m response, output_content_type\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train_sagemaker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SageMaker MXNet Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_instance_type = 'ml.p3.2xlarge'\n",
    "\n",
    "m = MXNet(entry_point='train_sagemaker.py',\n",
    "          py_version='py3',\n",
    "          role=role, \n",
    "          train_instance_count=1, \n",
    "          train_instance_type=train_instance_type,\n",
    "          output_path=output_location,\n",
    "          hyperparameters={'num-gpus': 1,\n",
    "                           'epochs': 10,\n",
    "                           'optimizer': 'adam',\n",
    "                           'batch-size':256},\n",
    "         input_mode='File',\n",
    "         train_max_run=7200,\n",
    "         framework_version='1.3.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fit MXNet Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-09 08:29:48 Starting - Starting the training job...\n",
      "2020-01-09 08:29:50 Starting - Launching requested ML instances......\n",
      "2020-01-09 08:30:54 Starting - Preparing the instances for training......\n",
      "2020-01-09 08:32:11 Downloading - Downloading input data\n",
      "2020-01-09 08:32:11 Training - Downloading the training image...\n",
      "2020-01-09 08:32:32 Training - Training image download completed. Training in progress.\u001b[34m2020-01-09 08:32:33,492 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-01-09 08:32:33,519 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HP_BATCH-SIZE': '256', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_HP_EPOCHS': '10', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_LOG_LEVEL': '20', 'SM_HOSTS': '[\"algo-1\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNELS': '[\"train\"]', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"epochs\":10,\"num-gpus\":1,\"optimizer\":\"adam\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2020-01-09-08-29-48-513\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-412868550678/sagemaker-mxnet-2020-01-09-08-29-48-513/source/sourcedir.tar.gz\",\"module_name\":\"train_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sagemaker.py\"}', 'SM_USER_ENTRY_POINT': 'train_sagemaker.py', 'SM_HP_NUM-GPUS': '1', 'SM_USER_ARGS': '[\"--batch-size\",\"256\",\"--epochs\",\"10\",\"--num-gpus\",\"1\",\"--optimizer\",\"adam\"]', 'SM_MODULE_NAME': 'train_sagemaker', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_HPS': '{\"batch-size\":256,\"epochs\":10,\"num-gpus\":1,\"optimizer\":\"adam\"}', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_DIR': 's3://sagemaker-us-east-1-412868550678/sagemaker-mxnet-2020-01-09-08-29-48-513/source/sourcedir.tar.gz', 'SM_HP_OPTIMIZER': 'adam', 'SM_NUM_CPUS': '8', 'SM_INPUT_DATA_CONFIG': '{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_NUM_GPUS': '1', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config'}\u001b[0m\n",
      "\u001b[34m2020-01-09 08:33:29,574 sagemaker-containers INFO     Module train_sagemaker does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-09 08:33:29,574 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-09 08:33:29,575 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-09 08:33:29,575 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train-sagemaker\n",
      "  Running setup.py bdist_wheel for train-sagemaker: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train-sagemaker: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iel31p0o/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train-sagemaker\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train-sagemaker\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-sagemaker-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 19.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-01-09 08:33:31,108 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_name\": \"train_sagemaker\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"is_master\": true,\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"user_entry_point\": \"train_sagemaker.py\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 10,\n",
      "        \"batch-size\": 256,\n",
      "        \"num-gpus\": 1,\n",
      "        \"optimizer\": \"adam\"\n",
      "    },\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-412868550678/sagemaker-mxnet-2020-01-09-08-29-48-513/source/sourcedir.tar.gz\",\n",
      "    \"log_level\": 20,\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"job_name\": \"sagemaker-mxnet-2020-01-09-08-29-48-513\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adam\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"epochs\":10,\"num-gpus\":1,\"optimizer\":\"adam\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-mxnet-2020-01-09-08-29-48-513\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-412868550678/sagemaker-mxnet-2020-01-09-08-29-48-513/source/sourcedir.tar.gz\",\"module_name\":\"train_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"256\",\"--epochs\",\"10\",\"--num-gpus\",\"1\",\"--optimizer\",\"adam\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_sagemaker\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":256,\"epochs\":10,\"num-gpus\":1,\"optimizer\":\"adam\"}\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-412868550678/sagemaker-mxnet-2020-01-09-08-29-48-513/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train_sagemaker --batch-size 256 --epochs 10 --num-gpus 1 --optimizer adam\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/datasets/mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-images-idx3-ubyte.gz...\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/datasets/mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-labels-idx1-ubyte.gz...\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-01-09 08:33:53,592 INFO __main__: Epoch[0] Loss:0.241 Acc:0.926|0.965 Perf: 6394.7 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:34:03,043 INFO __main__: Epoch[1] Loss:0.113 Acc:0.965|0.975 Perf: 6348.6 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:34:13,297 INFO __main__: Epoch[2] Loss:0.084 Acc:0.974|0.980 Perf: 5851.8 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:34:23,168 INFO __main__: Epoch[3] Loss:0.069 Acc:0.978|0.980 Perf: 6078.7 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:34:33,011 INFO __main__: Epoch[4] Loss:0.061 Acc:0.980|0.982 Perf: 6095.7 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:34:43,314 INFO __main__: Epoch[5] Loss:0.060 Acc:0.981|0.986 Perf: 5823.6 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:34:53,216 INFO __main__: Epoch[6] Loss:0.052 Acc:0.983|0.982 Perf: 6059.9 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:35:03,277 INFO __main__: Epoch[7] Loss:0.058 Acc:0.982|0.987 Perf: 5963.7 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:35:12,422 INFO __main__: Epoch[8] Loss:0.053 Acc:0.984|0.987 Perf: 6561.7 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:35:22,424 INFO __main__: Epoch[9] Loss:0.049 Acc:0.985|0.985 Perf: 5999.0 img/sec\u001b[0m\n",
      "\u001b[34m2020-01-09 08:35:22,428 INFO __main__: Saved model params\u001b[0m\n",
      "\u001b[34m2020-01-09 08:35:22,428 INFO __main__: End of training\u001b[0m\n",
      "\u001b[34m2020-01-09 08:35:22,761 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-09 08:35:31 Uploading - Uploading generated training model\n",
      "2020-01-09 08:35:31 Completed - Training job completed\n",
      "Training seconds: 217\n",
      "Billable seconds: 217\n"
     ]
    }
   ],
   "source": [
    "m.fit({'train': data_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deploy Trained model to a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = m.deploy(initial_instance_count=1,\n",
    "                     endpoint_name=\"mxnet-sagemaker-demo-endpoint\",\n",
    "                     instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
